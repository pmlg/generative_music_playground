{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Piano Music with Transformer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-RWsbrhmPpP",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI5g-x4foZls",
        "colab_type": "text"
      },
      "source": [
        "# Generating Piano Music with Transformer\n",
        "### ___Ian Simon, Anna Huang, Jesse Engel, Curtis \"Fjord\" Hawthorne___\n",
        "\n",
        "This Colab notebook lets you play with pretrained [Transformer](https://arxiv.org/abs/1706.03762) models for piano music generation, based on the [Music Transformer](http://g.co/magenta/music-transformer) model introduced by [Huang et al.](https://arxiv.org/abs/1809.04281) in 2018.\n",
        "\n",
        "The models used here were trained on over 10,000 hours of piano recordings from YouTube, transcribed using [Onsets and Frames](http://g.co/magenta/onsets-frames) and represented using the event vocabulary from [Performance RNN](http://g.co/magenta/performance-rnn).\n",
        "\n",
        "Unlike the original Music Transformer paper, this notebook uses attention based on absolute instead of relative position; we may add models that use relative attention at some point in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDMQbHPYVKmV",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tciXVi5eWG_1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Setup Environment\n",
        "#@markdown Copy model checkpoints and some auxiliary data from\n",
        "#@markdown Google Cloud Storage.  Also install and import\n",
        "#@markdown Python dependencies needed for running the\n",
        "#@markdown Transformer models.\n",
        "#@markdown\n",
        "#@markdown This cell may take a few minutes to run.\n",
        "\n",
        "print('Copying checkpoints and Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')\n",
        "!gsutil -q -m cp -r gs://magentadata/models/music_transformer/* /content/\n",
        "!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU magenta pyfluidsynth\n",
        "\n",
        "import ctypes.util\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return ctypes.util.find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries...')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "from tensor2tensor.utils import decoding\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.score2perf import score2perf\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3URxzTQyXfdO",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Definitions\n",
        "#@markdown Define a few constants and helper functions.\n",
        "\n",
        "SF2_PATH = '/content/Yamaha-C5-Salamander-JNv5.1.sf2'\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "# Upload a MIDI file and convert to NoteSequence.\n",
        "def upload_midi():\n",
        "  data = list(files.upload().values())\n",
        "  if len(data) > 1:\n",
        "    print('Multiple files uploaded; using only one.')\n",
        "  return mm.midi_to_note_sequence(data[0])\n",
        "\n",
        "# Decode a list of IDs.\n",
        "def decode(ids, encoder):\n",
        "  ids = list(ids)\n",
        "  if text_encoder.EOS_ID in ids:\n",
        "    ids = ids[:ids.index(text_encoder.EOS_ID)]\n",
        "  return encoder.decode(ids)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl3oY0w8gBJh",
        "colab_type": "text"
      },
      "source": [
        "# Piano Performance Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBngSJvP_En7",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Setup and Load Checkpoint\n",
        "#@markdown Set up generation from an unconditional Transformer\n",
        "#@markdown model.\n",
        "\n",
        "model_name = 'transformer'\n",
        "hparams_set = 'transformer_tpu'\n",
        "ckpt_path = '/content/checkpoints/unconditional_model_16.ckpt'\n",
        "\n",
        "class PianoPerformanceLanguageModelProblem(score2perf.Score2PerfProblem):\n",
        "  @property\n",
        "  def add_eos_symbol(self):\n",
        "    return True\n",
        "\n",
        "problem = PianoPerformanceLanguageModelProblem()\n",
        "unconditional_encoders = problem.get_feature_encoders()\n",
        "\n",
        "# Set up HParams.\n",
        "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
        "trainer_lib.add_problem_hparams(hparams, problem)\n",
        "hparams.num_hidden_layers = 16\n",
        "hparams.sampling_method = 'random'\n",
        "\n",
        "# Set up decoding HParams.\n",
        "decode_hparams = decoding.decode_hparams()\n",
        "decode_hparams.alpha = 0.0\n",
        "decode_hparams.beam_size = 1\n",
        "\n",
        "# Create Estimator.\n",
        "run_config = trainer_lib.create_run_config(hparams)\n",
        "estimator = trainer_lib.create_estimator(\n",
        "    model_name, hparams, run_config,\n",
        "    decode_hparams=decode_hparams)\n",
        "\n",
        "# Create input generator (so we can adjust priming and\n",
        "# decode length on the fly).\n",
        "def input_generator():\n",
        "  global targets\n",
        "  global decode_length\n",
        "  while True:\n",
        "    yield {\n",
        "        'targets': np.array([targets], dtype=np.int32),\n",
        "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
        "    }\n",
        "\n",
        "# These values will be changed by subsequent cells.\n",
        "targets = []\n",
        "decode_length = 0\n",
        "\n",
        "# Start the Estimator, loading from the specified checkpoint.\n",
        "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
        "unconditional_samples = estimator.predict(\n",
        "    input_fn, checkpoint_path=ckpt_path)\n",
        "\n",
        "# \"Burn\" one.\n",
        "_ = next(unconditional_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ybYgKSgIt-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Generate from Scratch\n",
        "#@markdown Generate a piano performance from scratch.\n",
        "#@markdown\n",
        "#@markdown This can take a minute or so depending on the length\n",
        "#@markdown of the performance the model ends up generating.\n",
        "#@markdown Because we use a \n",
        "#@markdown [representation](http://g.co/magenta/performance-rnn)\n",
        "#@markdown where each event corresponds to a variable amount of\n",
        "#@markdown time, the actual number of seconds generated may vary.\n",
        "\n",
        "targets = []\n",
        "decode_length = 1024\n",
        "\n",
        "# Generate sample events.\n",
        "sample_ids = next(unconditional_samples)['outputs']\n",
        "\n",
        "# Decode to NoteSequence.\n",
        "midi_filename = decode(\n",
        "    sample_ids,\n",
        "    encoder=unconditional_encoders['targets'])\n",
        "unconditional_ns = mm.midi_file_to_note_sequence(midi_filename)\n",
        "\n",
        "# Play and plot.\n",
        "mm.play_sequence(\n",
        "    unconditional_ns,\n",
        "    synth=mm.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "mm.plot_sequence(unconditional_ns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R7s3MmldBBB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download Performance as MIDI\n",
        "#@markdown Download generated performance as MIDI (optional).\n",
        "\n",
        "mm.sequence_proto_to_midi_file(\n",
        "    unconditional_ns, '/tmp/unconditional.mid')\n",
        "files.download('/tmp/unconditional.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in5GRrDqKj-f",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Choose Priming Sequence\n",
        "#@markdown Here you can choose a priming sequence to be continued\n",
        "#@markdown by the model.  We have provided a few, or you can\n",
        "#@markdown upload your own MIDI file.\n",
        "#@markdown\n",
        "#@markdown Set `max_primer_seconds` below to trim the primer to a\n",
        "#@markdown fixed number of seconds (this will have no effect if\n",
        "#@markdown the primer is already shorter than `max_primer_seconds`).\n",
        "\n",
        "filenames = {\n",
        "    'C major arpeggio': '/content/primers/c_major_arpeggio.mid',\n",
        "    'C major scale': '/content/primers/c_major_scale.mid',\n",
        "    'Clair de Lune': '/content/primers/clair_de_lune.mid',\n",
        "}\n",
        "primer = 'C major scale'  #@param ['C major arpeggio', 'C major scale', 'Clair de Lune', 'Upload your own!']\n",
        "\n",
        "if primer == 'Upload your own!':\n",
        "  primer_ns = upload_midi()\n",
        "else:\n",
        "  # Use one of the provided primers.\n",
        "  primer_ns = mm.midi_file_to_note_sequence(filenames[primer])\n",
        "\n",
        "# Handle sustain pedal in the primer.\n",
        "primer_ns = mm.apply_sustain_control_changes(primer_ns)\n",
        "\n",
        "# Trim to desired number of seconds.\n",
        "max_primer_seconds = 20  #@param {type:\"slider\", min:1, max:120}\n",
        "if primer_ns.total_time > max_primer_seconds:\n",
        "  print('Primer is longer than %d seconds, truncating.' % max_primer_seconds)\n",
        "  primer_ns = mm.extract_subsequence(\n",
        "      primer_ns, 0, max_primer_seconds)\n",
        "\n",
        "# Remove drums from primer if present.\n",
        "if any(note.is_drum for note in primer_ns.notes):\n",
        "  print('Primer contains drums; they will be removed.')\n",
        "  notes = [note for note in primer_ns.notes if not note.is_drum]\n",
        "  del primer_ns.notes[:]\n",
        "  primer_ns.notes.extend(notes)\n",
        "\n",
        "# Set primer instrument and program.\n",
        "for note in primer_ns.notes:\n",
        "  note.instrument = 1\n",
        "  note.program = 0\n",
        "\n",
        "# Play and plot the primer.\n",
        "mm.play_sequence(\n",
        "    primer_ns,\n",
        "    synth=mm.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "mm.plot_sequence(primer_ns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O4niaxYPWyR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Generate Continuation\n",
        "#@markdown Continue a piano performance, starting with the\n",
        "#@markdown chosen priming sequence.\n",
        "\n",
        "targets = unconditional_encoders['targets'].encode_note_sequence(\n",
        "    primer_ns)\n",
        "\n",
        "# Remove the end token from the encoded primer.\n",
        "targets = targets[:-1]\n",
        "\n",
        "decode_length = max(0, 4096 - len(targets))\n",
        "if len(targets) >= 4096:\n",
        "  print('Primer has more events than maximum sequence length; nothing will be generated.')\n",
        "\n",
        "# Generate sample events.\n",
        "sample_ids = next(unconditional_samples)['outputs']\n",
        "\n",
        "# Decode to NoteSequence.\n",
        "midi_filename = decode(\n",
        "    sample_ids,\n",
        "    encoder=unconditional_encoders['targets'])\n",
        "ns = mm.midi_file_to_note_sequence(midi_filename)\n",
        "\n",
        "# Append continuation to primer.\n",
        "continuation_ns = mm.concatenate_sequences([primer_ns, ns])\n",
        "\n",
        "# Play and plot.\n",
        "mm.play_sequence(\n",
        "    continuation_ns,\n",
        "    synth=mm.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "mm.plot_sequence(continuation_ns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwg_8SI4eIyy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download Continuation as MIDI\n",
        "#@markdown Download performance (primer + generated continuation)\n",
        "#@markdown as MIDI (optional).\n",
        "\n",
        "mm.sequence_proto_to_midi_file(\n",
        "    continuation_ns, '/tmp/continuation.mid')\n",
        "files.download('/tmp/continuation.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loV8bwJ8fOR_",
        "colab_type": "text"
      },
      "source": [
        "# Melody-Conditioned Piano Performance Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFnUHAk1g_rc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Setup and Load Checkpoint\n",
        "#@markdown Set up generation from a melody-conditioned\n",
        "#@markdown Transformer model.\n",
        "\n",
        "model_name = 'transformer'\n",
        "hparams_set = 'transformer_tpu'\n",
        "ckpt_path = '/content/checkpoints/melody_conditioned_model_16.ckpt'\n",
        "\n",
        "class MelodyToPianoPerformanceProblem(score2perf.AbsoluteMelody2PerfProblem):\n",
        "  @property\n",
        "  def add_eos_symbol(self):\n",
        "    return True\n",
        "\n",
        "problem = MelodyToPianoPerformanceProblem()\n",
        "melody_conditioned_encoders = problem.get_feature_encoders()\n",
        "\n",
        "# Set up HParams.\n",
        "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
        "trainer_lib.add_problem_hparams(hparams, problem)\n",
        "hparams.num_hidden_layers = 16\n",
        "hparams.sampling_method = 'random'\n",
        "\n",
        "# Set up decoding HParams.\n",
        "decode_hparams = decoding.decode_hparams()\n",
        "decode_hparams.alpha = 0.0\n",
        "decode_hparams.beam_size = 1\n",
        "\n",
        "# Create Estimator.\n",
        "run_config = trainer_lib.create_run_config(hparams)\n",
        "estimator = trainer_lib.create_estimator(\n",
        "    model_name, hparams, run_config,\n",
        "    decode_hparams=decode_hparams)\n",
        "\n",
        "# These values will be changed by the following cell.\n",
        "inputs = []\n",
        "decode_length = 0\n",
        "\n",
        "# Create input generator.\n",
        "def input_generator():\n",
        "  global inputs\n",
        "  while True:\n",
        "    yield {\n",
        "        'inputs': np.array([[inputs]], dtype=np.int32),\n",
        "        'targets': np.zeros([1, 0], dtype=np.int32),\n",
        "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
        "    }\n",
        "\n",
        "# Start the Estimator, loading from the specified checkpoint.\n",
        "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
        "melody_conditioned_samples = estimator.predict(\n",
        "    input_fn, checkpoint_path=ckpt_path)\n",
        "\n",
        "# \"Burn\" one.\n",
        "_ = next(melody_conditioned_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqWN4dEDLVdQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Choose Melody\n",
        "#@markdown Here you can choose a melody to be accompanied by the\n",
        "#@markdown model.  We have provided a few, or you can upload a\n",
        "#@markdown MIDI file; if your MIDI file is polyphonic, the notes\n",
        "#@markdown with highest pitch will be used as the melody.\n",
        "\n",
        "# Tokens to insert between melody events.\n",
        "event_padding = 2 * [mm.MELODY_NO_EVENT]\n",
        "\n",
        "melodies = {\n",
        "    'Mary Had a Little Lamb': [\n",
        "        64, 62, 60, 62, 64, 64, 64, mm.MELODY_NO_EVENT,\n",
        "        62, 62, 62, mm.MELODY_NO_EVENT,\n",
        "        64, 67, 67, mm.MELODY_NO_EVENT,\n",
        "        64, 62, 60, 62, 64, 64, 64, 64,\n",
        "        62, 62, 64, 62, 60, mm.MELODY_NO_EVENT,\n",
        "        mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT\n",
        "    ],\n",
        "    'Row Row Row Your Boat': [\n",
        "        60, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        60, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        60, mm.MELODY_NO_EVENT, 62,\n",
        "        64, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        64, mm.MELODY_NO_EVENT, 62,\n",
        "        64, mm.MELODY_NO_EVENT, 65,\n",
        "        67, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        72, 72, 72, 67, 67, 67, 64, 64, 64, 60, 60, 60,\n",
        "        67, mm.MELODY_NO_EVENT, 65,\n",
        "        64, mm.MELODY_NO_EVENT, 62,\n",
        "        60, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT,\n",
        "        mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT, mm.MELODY_NO_EVENT\n",
        "    ],\n",
        "    'Twinkle Twinkle Little Star': [\n",
        "        60, 60, 67, 67, 69, 69, 67, mm.MELODY_NO_EVENT,\n",
        "        65, 65, 64, 64, 62, 62, 60, mm.MELODY_NO_EVENT,\n",
        "        67, 67, 65, 65, 64, 64, 62, mm.MELODY_NO_EVENT,\n",
        "        67, 67, 65, 65, 64, 64, 62, mm.MELODY_NO_EVENT,\n",
        "        60, 60, 67, 67, 69, 69, 67, mm.MELODY_NO_EVENT,\n",
        "        65, 65, 64, 64, 62, 62, 60, mm.MELODY_NO_EVENT        \n",
        "    ]\n",
        "}\n",
        "\n",
        "melody = 'Twinkle Twinkle Little Star'  #@param ['Mary Had a Little Lamb', 'Row Row Row Your Boat', 'Twinkle Twinkle Little Star', 'Upload your own!']\n",
        "\n",
        "if melody == 'Upload your own!':\n",
        "  # Extract melody from user-uploaded MIDI file.\n",
        "  melody_ns = upload_midi()\n",
        "  melody_instrument = mm.infer_melody_for_sequence(melody_ns)\n",
        "  notes = [note for note in melody_ns.notes\n",
        "           if note.instrument == melody_instrument]\n",
        "  del melody_ns.notes[:]\n",
        "  melody_ns.notes.extend(\n",
        "      sorted(notes, key=lambda note: note.start_time))\n",
        "  for i in range(len(melody_ns.notes) - 1):\n",
        "    melody_ns.notes[i].end_time = melody_ns.notes[i + 1].start_time\n",
        "  inputs = melody_conditioned_encoders['inputs'].encode_note_sequence(\n",
        "      melody_ns)\n",
        "else:\n",
        "  # Use one of the provided melodies.\n",
        "  events = [event + 12 if event != mm.MELODY_NO_EVENT else event\n",
        "            for e in melodies[melody]\n",
        "            for event in [e] + event_padding]\n",
        "  inputs = melody_conditioned_encoders['inputs'].encode(\n",
        "      ' '.join(str(e) for e in events))\n",
        "  melody_ns = mm.Melody(events).to_sequence(qpm=150)\n",
        "\n",
        "# Play and plot the melody.\n",
        "mm.play_sequence(\n",
        "    melody_ns,\n",
        "    synth=mm.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "mm.plot_sequence(melody_ns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnAZsIYsfXWV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Generate Accompaniment for Melody\n",
        "#@markdown Generate a piano performance consisting of the chosen\n",
        "#@markdown melody plus accompaniment.\n",
        "\n",
        "# Generate sample events.\n",
        "decode_length = 4096\n",
        "sample_ids = next(melody_conditioned_samples)['outputs']\n",
        "\n",
        "# Decode to NoteSequence.\n",
        "midi_filename = decode(\n",
        "    sample_ids,\n",
        "    encoder=melody_conditioned_encoders['targets'])\n",
        "accompaniment_ns = mm.midi_file_to_note_sequence(midi_filename)\n",
        "\n",
        "# Play and plot.\n",
        "mm.play_sequence(\n",
        "    accompaniment_ns,\n",
        "    synth=mm.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "mm.plot_sequence(accompaniment_ns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fFhZbhIeS2f",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download Accompaniment as MIDI\n",
        "#@markdown Download accompaniment performance as MIDI (optional).\n",
        "\n",
        "mm.sequence_proto_to_midi_file(\n",
        "    accompaniment_ns, '/tmp/accompaniment.mid')\n",
        "files.download('/tmp/accompaniment.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}